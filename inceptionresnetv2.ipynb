{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# for keras\n",
    "from classification_models.keras import Classifiers\n",
    "\n",
    "# for tensorflow keras\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_train_path = \"./Dataset/Train/small/smaller/Fake_small_15000\"\n",
    "real_train_path = \"./Dataset/Train/small/smaller/Real_small_15000\"\n",
    "train_path = './Dataset/Train/small/smaller'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(fake_train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30002 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=(100,100),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=45\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels in train_dataset.take(1):\n",
    "#     break\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# for i in range(10):\n",
    "#     plt.subplot(8, 8, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(labels[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionresnetv2, preprocess_input = Classifiers.get('inceptionresnetv2')\n",
    "base_model = inceptionresnetv2(include_top = False, input_shape=(100, 100, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_resnet_v2 (Functi  (None, 1, 1, 1536)       54336736  \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1536)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              1573888   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,435,937\n",
      "Trainable params: 56,375,393\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.47392786>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    break\n",
    "\n",
    "max(images[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 262s 256ms/step - loss: 0.1649 - accuracy: 0.9357\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 210s 224ms/step - loss: 0.0814 - accuracy: 0.9706\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 196s 208ms/step - loss: 0.0626 - accuracy: 0.9760\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 195s 208ms/step - loss: 0.0565 - accuracy: 0.9791\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 195s 208ms/step - loss: 0.0514 - accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c63df8250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "The image is predicted to be a real with a confidence of 86.09%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = './Just as it is/fake_146.jpg'  # Replace with your image path\n",
    "img = image.load_img(img_path, target_size=(100, 100))  # Resize to match model input shape\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array/255.0\n",
    "# img_array = tf.image.per_image_standardization(img_array)  # Standardize the image\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict with the model\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Interpretation of the result\n",
    "if prediction[0] > 0.5:\n",
    "    print(f\"The image is predicted to be a real with a confidence of {prediction[0][0]*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"The image is predicted to be deepfake with a confidence of {(1-prediction[0][0])*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 files belonging to 2 classes.\n",
      "938/938 [==============================] - 66s 67ms/step - loss: 0.0620 - accuracy: 0.9709\n"
     ]
    }
   ],
   "source": [
    "test_path = './1000_videos/test'\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    image_size=(100,100),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.0620 - accuracy: 0.9709"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
